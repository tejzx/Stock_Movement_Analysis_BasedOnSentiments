{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4c4691f-7f25-43d4-ab06-32cb05701327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* Running on public URL: https://806825bf17d9004d22.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://806825bf17d9004d22.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reach\\AppData\\Local\\Temp\\ipykernel_16676\\2533167807.py:61: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.countplot(data=dataframe, x=\"sentiment\", palette=\"coolwarm\")\n",
      "C:\\Users\\reach\\AppData\\Local\\Temp\\ipykernel_16676\\2533167807.py:86: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(data=dataframe, x=\"sentiment\", y=\"text_length\", palette=\"coolwarm\")\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import gradio as gr\n",
    "\n",
    "# Reddit API credentials\n",
    "CLIENT_ID = \"WTX0oyGqfao_shOgjF0psw\"\n",
    "CLIENT_SECRET = \"n6A_hUK_TfBgGzN00yZKA27JzDeYig\"\n",
    "USER_AGENT = \"StockMovement/1.0 by SandwichCharming4204\"\n",
    "\n",
    "# Authenticate with Reddit API\n",
    "def authenticate_reddit():\n",
    "    reddit = praw.Reddit(\n",
    "        client_id=CLIENT_ID,\n",
    "        client_secret=CLIENT_SECRET,\n",
    "        user_agent=USER_AGENT\n",
    "    )\n",
    "    return reddit\n",
    "\n",
    "# Scrape posts from a subreddit\n",
    "def scrape_reddit(subreddit_name, limit=100):\n",
    "    reddit = authenticate_reddit()\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    posts = []\n",
    "    for post in subreddit.hot(limit=limit):\n",
    "        posts.append({'title': post.title, 'content': post.selftext, 'score': post.score, 'date': pd.to_datetime(post.created_utc, unit='s')})\n",
    "    return pd.DataFrame(posts)\n",
    "\n",
    "# Preprocess and classify posts\n",
    "def preprocess_and_classify(dataframe, model, vectorizer):\n",
    "    dataframe['processed_content'] = dataframe['content'].fillna(\"\").str.lower()\n",
    "    X = vectorizer.transform(dataframe['processed_content'])\n",
    "    predictions = model.predict(X)\n",
    "    dataframe['sentiment'] = predictions\n",
    "    return dataframe\n",
    "\n",
    "# Train the sentiment analysis model\n",
    "def train_model():\n",
    "    data = pd.DataFrame({\n",
    "        'text': ['This stock is great!', 'Poor performance', 'Highly recommended!', 'Not worth the investment'],\n",
    "        'label': [1, 0, 1, 0]\n",
    "    })\n",
    "    X = data['text']\n",
    "    y = data['label']\n",
    "    vectorizer = CountVectorizer()\n",
    "    X_vect = vectorizer.fit_transform(X)\n",
    "    model = MultinomialNB()\n",
    "    model.fit(X_vect, y)\n",
    "    return model, vectorizer\n",
    "\n",
    "# Initialize the model and vectorizer\n",
    "model, vectorizer = train_model()\n",
    "\n",
    "# Create visualizations\n",
    "def create_visualizations(dataframe):\n",
    "    # Sentiment Distribution\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.countplot(data=dataframe, x=\"sentiment\", palette=\"coolwarm\")\n",
    "    plt.title(\"Sentiment Distribution\")\n",
    "    plt.xlabel(\"Sentiment (0 = Negative, 1 = Positive)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.tight_layout()\n",
    "    sentiment_distribution_path = \"sentiment_distribution.png\"\n",
    "    plt.savefig(sentiment_distribution_path)\n",
    "    plt.close()\n",
    "\n",
    "    # Sentiment Scores Over Time\n",
    "    if not dataframe.empty and 'date' in dataframe.columns:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.lineplot(data=dataframe, x=\"date\", y=\"score\", hue=\"sentiment\", marker=\"o\", palette=\"coolwarm\")\n",
    "        plt.title(\"Sentiment Scores Over Time\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Sentiment Score\")\n",
    "        plt.legend(title=\"Sentiment\", loc=\"upper left\")\n",
    "        plt.tight_layout()\n",
    "        sentiment_scores_time_path = \"sentiment_scores_time.png\"\n",
    "        plt.savefig(sentiment_scores_time_path)\n",
    "        plt.close()\n",
    "\n",
    "    # Text Length vs Sentiment\n",
    "    dataframe[\"text_length\"] = dataframe[\"content\"].fillna(\"\").apply(len)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.boxplot(data=dataframe, x=\"sentiment\", y=\"text_length\", palette=\"coolwarm\")\n",
    "    plt.title(\"Text Length by Sentiment\")\n",
    "    plt.xlabel(\"Sentiment (0 = Negative, 1 = Positive)\")\n",
    "    plt.ylabel(\"Text Length\")\n",
    "    plt.tight_layout()\n",
    "    text_length_sentiment_path = \"text_length_sentiment.png\"\n",
    "    plt.savefig(text_length_sentiment_path)\n",
    "    plt.close()\n",
    "\n",
    "    return sentiment_distribution_path, sentiment_scores_time_path, text_length_sentiment_path\n",
    "\n",
    "# Gradio interface\n",
    "def analyze_sentiment(subreddit_name, limit=10):\n",
    "    posts_df = scrape_reddit(subreddit_name, limit)\n",
    "    result_df = preprocess_and_classify(posts_df, model, vectorizer)\n",
    "    sentiment_distribution, sentiment_scores_time, text_length_sentiment = create_visualizations(result_df)\n",
    "    return sentiment_distribution, sentiment_scores_time, text_length_sentiment\n",
    "\n",
    "gr.Interface(\n",
    "    fn=analyze_sentiment,\n",
    "    inputs=[gr.Textbox(label=\"Subreddit Name\"), gr.Slider(10, 100, label=\"Number of Posts\")],\n",
    "    outputs=[\n",
    "        gr.Image(label=\"Sentiment Distribution\"),\n",
    "        gr.Image(label=\"Sentiment Scores Over Time\"),\n",
    "        gr.Image(label=\"Text Length by Sentiment\")\n",
    "    ],\n",
    "    title=\"Reddit Stock Sentiment Analyzer with Visualizations\"\n",
    ").launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99bc993-1116-43ab-8538-51742ac7cfd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
